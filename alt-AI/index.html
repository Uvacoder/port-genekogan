<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
   "http://www.w3.org/TR/html4/loose.dtd">

<html lang="en">
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>alt-AI</title>
	<link rel="stylesheet" type="text/css" href="css/style.css">
	<script src="js/jquery-1.8.3.min.js"></script>
</head>
<body>
	
	<p/>
	
	<div id="d_people">
	</div>

	<div style="display: none;" id="d_tickets">
		<h2>Talks</h2>
		<p><strike>Early-bird (all 3 days of talks)</b> : <a href="http://www.brownpapertickets.com/event/2542898">sold out!</a></strike></p>
		<p><strike>All 3 days of talks : <a href="http://www.brownpapertickets.com/event/2547152">sold out!</a></strike></p>
		<p>Talks, Friday May 20 : <a href="http://www.brownpapertickets.com/event/2547568">Tickets</a></p>
		<p><strike>Talks, Saturday May 21 : <a href="http://www.brownpapertickets.com/event/2547571">sold out!</a></strike></p>
		<p><strike>Talks, Sunday May 22 : <a href="http://www.brownpapertickets.com/event/2547573">sold out!</a></strike></p>
		<p/>&nbsp;
		<h2>Workshops</h2>
		<p>Real-time performance with Wekinator (Rebecca Fiebrink) : <a href="http://www.brownpapertickets.com/event/2544515">Tickets</a></p>
		<p>ML 101: Reverse Engineering Phenomena (Francis Tseng) : <a href="http://www.brownpapertickets.com/event/2544522">Tickets</a></p>
		<p>Visualizing high-dimensional data (Gene Kogan) : <a href="http://www.brownpapertickets.com/event/2544526">Tickets</a></p>
		<p/>
		<p/>&nbsp;
		<h2>Exhibition</h2>
		<p>The exhibition will be free and open to the public! More details later via <a href="embed.html">mailing list</a>.</p>
	</div>

	<div style="display: none;" id="d_contact">
		<h2>Contact</h2>
		<h3>alt-AI was hosted at <a href="http://www.sfpc.io">SFPC</a> and organized by <a href="http://laurengardner.com/">Lauren Gardner</a> and <a href="http://www.genekogan.com">Gene Kogan</a>.
		<h3>Schedule, ticketing, and financial support: <a href="mailto:Lauren@sfpc.io">Lauren@sfpc.io</a></h3>
		<h3>Press inquiries: <a href="mailto:Taeyoon@sfpc.io">Taeyoon@sfpc.io</a></h3>
		<h3>Exhibition and programming: <a href="mailto:kogan.gene@gmail.com">kogan.gene@gmail.com</a></h3>
	</div>

	<div style="display: none;" id="d_where">
		<h2><a href="http://blog.sfpc.io/post/133489114416/how-to-get-to-sfpc">How to get to SFPC</a></h2>
		
		<p>We are located in 155 Bank street, NYC. It&rsquo;s about 10 minutes walking distance from 14th street [A,C,L] and Christopher st [1] subway stations.&nbsp;</p><p>On Bank street, pass the New School for Drama. 155 Bank street is part of the WestBeth. There are scaffolding and fence in the courtyard. Walk to the west end of the courtyard and follow the arrow, pass the Michelson studio and find SFPC sign. There&rsquo;s a giant window and projection that will be screening students work. Walk through a door and you will see our space. We are on the ground floor. &nbsp;</p><p><br></p>
		<center>
			<img src="https://c2.staticflickr.com/6/5816/22504854763_0f05f37b3f_o.gif" alt="image"><p>gif by <a href="http://andydayton.com/">Andy Dayton</a>.&nbsp;</p><figure data-orig-width="2064" data-orig-height="1114" class="tmblr-full"><img src="http://65.media.tumblr.com/9fb209bdac9682f0e0ec4b9a5b1abf96/tumblr_inline_ny171nrpqP1qlm02g_500.jpg" alt="image" data-orig-width="2064" data-orig-height="1114" width="500" height="269"></figure><figure data-orig-width="1730" data-orig-height="1314" class="tmblr-full"><img src="http://67.media.tumblr.com/8813f90c8acbc29160de38fa4575815e/tumblr_inline_ny1754EQZr1qlm02g_500.jpg" alt="image" data-orig-width="1730" data-orig-height="1314" width="500" height="379"></figure>
		</center>
	</div>
	
	<div id="d_watch" style="display: none;">
		<div id="d_watch_top">
			<center>
			<h3>Thanks to <a href="http://livestream.com/internetsociety">Internet Society</a> for the <a href="http://livestream.com/internetsociety/alt-ai/">original livestream</a> and to <a href="http://www.sarahriazati.com/">Sarah Riazati</a> for the highlight video. <a href="">Back to main page</a></h3><p/>&nbsp;
			</center>
		</div>
		<p/>
		<div id="d_watch_left">
		</div>
		<div id="d_watch_right">
		</div>
	</div>
	
	<div style="display: none;" id="d_schedule">
		
		<h2>Exhibition</h2>
		<p>The exhibition will be free and open to the public! More details will be announced via <a href="embed.html">mailing list</a>.</p>
		<hr>
		<div class="sched_header"><h1>Friday 5.20</h1></div>
		<div class="sched_entry">
			<div class="sched_time">17:00</div>
			<div class="sched_description">Gallery opens!</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">18:45</div>
			<div class="sched_description">Opening remarks from SFPC</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">19:00</div>
			<div class="sched_description"><b>Talk:</b> Gene Kogan</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">19:30</div>
			<div class="sched_description"><b>Exhibition presentation:</b> Golan Levin, Cassie Tarakajian, Hannah Davis</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">20:30</div>
			<div class="sched_description"><b>Performance:</b> Jason Levine</div>
		</div>
		<hr>

		<div class="sched_header"><h1>Saturday 5.21</h1></div>
		<div class="sched_entry">
			<div class="sched_time">11:00</div>
			<div class="sched_description"><b>Workshop:</b> Real-time performance with Wekinator<br/>11:00 - 14:00, Instructor: Rebecca Fiebrink</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">14:00</div>
			<div class="sched_description"><b>Workshop:</b> ML 101: Reverse Engineering Phenomena<br/>14:00 - 17:00, Instructor: Francis Tseng</div>
		</div>
		
		<div class="sched_entry">
			<div class="sched_time">17:30</div>
			<div class="sched_description"><b>Talk:</b> Rebecca Fiebrink</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">18:00</div>
			<div class="sched_description"><b>Talk:</b> Mike Tyka</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">18:30</div>
			<div class="sched_description">&nbsp;[break]&nbsp;</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">19:00</div>
			<div class="sched_description"><b>Talk:</b> Heather Dewey-Hagborg</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">19:30</div>
			<div class="sched_description"><b>Talk:</b> Brian Whitman</div>
		</div>
		
		<hr>

		<div class="sched_header"><h1>Sunday 5.22</h1></div>
		<div class="sched_entry">
			<div class="sched_time">11:00</div>
			<div class="sched_description"><b>Workshop:</b> Visualizing high-dimensional data<br/>11:00 - 14:00, Instructor: Gene Kogan</div>
		</div>

		<div class="sched_entry">
			<div class="sched_time">16:00</div>
			<div class="sched_description"><b>Talk:</b> Allison Parrish</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">16:30</div>
			<div class="sched_description"><b>Talk:</b> Mario Klingemann</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">17:00</div>
			<div class="sched_description">&nbsp;[break]&nbsp;</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">17:30</div>
			<div class="sched_description"><b>Talk:</b> Lynn Cherny</div>
		</div>
		<div class="sched_entry">
			<div class="sched_time">18:00</div>
			<div class="sched_description"><b>Talk:</b> Kathryn Hume</div>
		</div>

		<hr>
	</div>
	
	<div style="display: none;" id="d_workshops">
		<div class="workshop" id="wekinator">
			<div class="wkshp_header">
				<img src="images/wkshp_wekinator.jpg" />
			</div>				
			<h2>Real-time performance with Wekinator</h2>
			<h3>Instructor: <a href="http://doc.gold.ac.uk/~mas01rf/Rebecca_Fiebrink_Goldsmiths/welcome.html">Rebecca Fiebrink</a></h3>
			<div class="description">
				Have you ever wanted to build a new musical instrument that responded to your gestures by making sound? Or create live visuals to accompany a dancer? Or create an interactive art installation that reacts to the movements or actions of an audience? If so, take this course!
				In this course, students will learn fundamental machine learning techniques that can be used to make sense of human gesture, musical audio, and other real-time data. The focus will be on learning about algorithms, software tools, and best practices that can be immediately employed in creating new real-time systems in the arts.
				<p/><h2><b><a href="http://www.brownpapertickets.com/event/2544515">Tickets</a></b></h2>
			</div>
		</div>
		
		<div class="workshop" id="ml101">
			<div class="wkshp_header">
				<img src="images/wkshp_ml101.jpg" />
			</div>				
			<h2>Machine Learning 101: Reverse Engineering Phenomena</h2>
			<h3>Instructor: <a href="http://frnsys.com">Francis Tseng</a></h3>
			<div class="description">
				Machine learning provides techniques that allow us to "reverse engineer" both natural and artificial phenomena in order to uncover their underlying processes. Given the ubiquity of black-box algorithmic control in society, the latter type of phenomena is probably more deserving of reverse engineering. In this workshop, the fundamental mindset and basic techniques of machine learning will be introduced through a narrative of a totally surveilled and quantified society based on the show <a href="https://en.wikipedia.org/wiki/Psycho-Pass">Psycho-Pass</a> and anxieties around programs like <a href="http://www.bbc.com/news/world-asia-china-34592186">Sesame Credit</a>. You'll learn how to think about the world in the "machine learning" way - from an intuitive mathematical perspective - and use popular Python programs to apply this new thinking to just about anything.
				<p/><h2><b><a href="http://www.brownpapertickets.com/event/2544522">Tickets</a></b></h2>
			</div>
		</div>

		<div class="workshop" id="visualization">
			<div class="wkshp_header">
				<img src="images/wkshp_tsne.jpg" />
			</div>
			<h2>Visualizing high-dimensional data</h2>
			<h3>Instructor: <a href="http://www.genekogan.com">Gene Kogan</a></h3>
			<div class="description">
				This class will introduce techniques for analyzing, organizing, and visualizing high-dimensional data in 2D. Case examples will include gridding a collection of images pre-analyzed by a neural network (in openFrameworks and python), and clustering Wikipedia articles based on content analysis (in python). In the process of generating these, we will introduce convolutional neural networks, tf-idf matrices for text processing, and the t-SNE dimensionality reduction algorithm. See <a href="www.genekogan.com/works/wiki-tSNE">here</a> and <a href="https://www.flickr.com/photos/genekogan/24873243915/in/dateposted-public/">here</a> for example projects.
				<p/><h2><b><a href="http://www.brownpapertickets.com/event/2544526">Tickets</a></b></h2>
			</div>
		</div>
	</div>
		
	
	<div id="d_exhibition" style="display: none;">
		<div id="d_exhibition_top">
			<center>
			<h3>Thanks to all our participating artists, and thanks to <a href="http://openframe.io">openframe</a> for organizing the displays! <a href="">Back to main page</a></h3><p/>&nbsp;
			</center>
		</div>
		<p/>
		<div id="d_exhibition_left">
		</div>
		<div id="d_exhibition_right">
		</div>
		<p/>
		<div id="d_exhibition_meta">
			<center><img src="images/openframe.jpg" /></center>
			<div id="open_call">
				<h1>Open call for artworks</h1>
				<h2>What format?</h2>
				<h3>We will have some number of electronic displays, courtesy of <a href="http://openframe.io">openframe</a>. Animated, web-based, and various other media can be proposed for these.</h3>
				<h3>Still images will either be shown on the displays, or printed.</hr>
				<h3>Installation or performance proposals are welcome, to the extent we'll have the space and means of accommodating them.</h3>
				<h2>Selection criteria</h1>
				<h3>Entries should have some connection to AI, machine learning, and adjacent fields. We take a broad view of the term.</h3>
				<h2>How to submit</h2>
				<h3>Entries can be changed at any time. <a href="http://goo.gl/forms/Lf46tfQpGR">Submit a proposal here.</a></h3>		
				<h2>Contact</h2>
				<h3>Questions, comments, suggestions? <a href="mailto:kogan.gene@gmail.com">E-mail us</a></h3>
			</div>
		</div>
	</div>


	<div id="main">
		
		<h1>alt-AI</h1>
		<h2>exploring the intersection of artificial intelligence and art</h2>
		<h2>2016 May 20 + 21 + 22</h2>
		<h2><a href="http://www.sfpc.io">@ school for poetic computation</a></h2>
		<h3>New York, NY &nbsp;&nbsp;<a href="https://www.google.com/maps/place/School+for+Poetic+Computation/@40.7365685,-74.0114828,17z/data=!3m1!4b1!4m2!3m1!1s0x89c259eb002ef131:0xa0fac3b59ef10e21">[map]</a>&nbsp;&nbsp;<a href="#where" onclick="javascript:goWhere();">[directions]</a></h3>
		<h3><a href="#watch" onclick="javascript:goWatch();">alt-AI is over! Watch the talks and highlight videos here.</a>
		<h3>
			alt-AI explores artificial intelligence through the lens of artistic practice. What role can artists, writers, coders, and curators play in mediating scientific research to the public? How do we critically examine the implications, artifacts, and applications that follow? 
		</h3>
		<h2>
			<br/>&nbsp;&nbsp;&nbsp;<a href="#people" onclick="javascript:goPeople();">people</a>
			&nbsp;&nbsp;&nbsp;<a href="#workshops" onclick="javascript:goWorkshops();">workshops</a>
			&nbsp;&nbsp;&nbsp;<a href="#exhibition" onclick="javascript:goExhibition();">exhibition</a>&nbsp;&nbsp;&nbsp;
			<p/>&nbsp;
			<a href="#schedule" onclick="javascript:goSchedule();">schedule</a>
			&nbsp;&nbsp;&nbsp;<a href="#tickets" onclick="javascript:goTickets();">tickets</a>
			&nbsp;&nbsp;&nbsp;<a href="#contact" onclick="javascript:goContact();">contact</a>
		</h2>
			<center><form style="width:85%;border:1px solid #eee;padding:10px;text-align:center;" action="https://tinyletter.com/alt-AI" method="post" target="popupwindow" onsubmit="window.open('https://tinyletter.com/alt-AI', 'popupwindow', 'scrollbars=yes,width=800,height=600');return true"><label for="tlemail"><h3>Sign-up for announcements (via <a href="https://tinyletter.com/alt-ai">TinyLetter</a>)</h3></label><input type="text" style="width:185px" name="email" id="tlemail" /><input type="hidden" value="1" name="embed"/><input type="submit" value="Subscribe" /><h4></h4></form></center>
	 </p>
	
	<p/>
	<h4>If you would like to support the conference, please <a href="#contact" onclick="javascript:goContact();">contact us</a>.<br/>Thank you to <a href="http://www.spotify.com">Spotify</a> for their generous donation.<br/></h4>
	
	</div>
	
	<script>
	
		var videos_loaded = false;
	
		function goPeople() {
			$("#d_people").show();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);		
		};
		function goWorkshops() {
			$("#d_people").hide();
			$("#d_workshops").show();
			$("#d_exhibition").hide();
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);		
		};
		function goExhibition() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").show();		
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$("#main").hide();
			$(window).scrollTop(0);		
		};
		function goSchedule() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();		
			$("#d_schedule").show();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);		
		};
		function goContact() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();		
			$("#d_schedule").hide();		
			$("#d_contact").show();	
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);		
		};
		function goTickets() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();		
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").show();	
			$("#d_where").hide();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);	
		};
		function goWhere() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();		
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").show();	
			$("#d_watch").hide();	
			$(window).scrollTop(0);	
		};
		function goWatch() {
			$("#d_people").hide();
			$("#d_workshops").hide();
			$("#d_exhibition").hide();		
			$("#d_schedule").hide();		
			$("#d_contact").hide();		
			$("#d_tickets").hide();	
			$("#d_where").hide();	
			$("#d_watch").show();	
			$("#main").hide();
			if (!videos_loaded) {
				load_highlight_videos();
				videos_loaded = true;
			}			
			$(window).scrollTop(0);	
		};

		function shuffle(a) {
	    	var j, x, i;
	    	for (i = a.length; i; i -= 1) {
	        	j = Math.floor(Math.random() * i);
	        	x = a[i - 1];
	        	a[i - 1] = a[j];
	        	a[j] = x;
	    	}
		}

		var peeps = [
		{name:'Allison Parrish', description:'Allison Parrish is a computer programmer, poet, educator and game designer who lives in Brooklyn. Her teaching and practice address the unusual phenomena that blossom when language and computers meet. Allison is currently the Digital Creative Writer-in-Residence at Fordham University and an adjunct professor/”something-in-residence” at NYU’s Interactive Telecommunications Program, where she teaches a course on writing computer programs that generate poetry.', href:'decontextualize.com', image:'allison.jpg', twitter:'aparrish'},
		{name:'Cassie Tarakajian', description:'Cassie Tarakajian is an artist and technologist based out of Brooklyn, NY. After studying electrical engineering and music at Johns Hopkins University, she worked as a software developer at Bloomberg and Big Human. Last fall she was an artist-in-residence at Pioneer Works, and she is currently a researcher-in-residence at DBRS labs working with machine learning, virtual reality, and cryptocurrency.', image:'cassie.jpg', href:'cassietarakajian.com', twitter:'hellothisiscass'},
		{name:'Heather Dewey-Hagborg', description:'Heather Dewey-Hagborg is a transdisciplinary artist and educator who is interested in art as research and critical practice. She has shown work internationally at events and venues including the World Economic Forum, Poland Mediations Bienniale, Norway Article Bienniale, Ars Electronica, Transmediale, Centre de Cultura Contemporània de Barcelona, the Science Gallery Dublin, PS1 MOMA, the New Museum, and Eyebeam Art and Technology Center in New York City. Her work has been widely discussed in the media, from the New York Times and the BBC to TED and Wired. She is an Assistant Professor of Art and Technology Studies at the School of the Art Institute of Chicago and a 2016 Creative Capital award grantee in the area of Emerging Fields.', image:'heather.jpg', href:'deweyhagborg.com', twitter:'hdeweyh'},
		{name:'Kathryn Hume', description:'Kathryn Hume leads sales and marketing for Fast Forward Labs, a machine intelligence research company, and teaches courses on law and technology at the University of Calgary. Prior to joining Fast Forward Labs, she advised global law firms on data privacy and security, and earned a doctorate in comparative literature from Stanford. She loves languages and drawing lessons from history to understand new technology.', href:'www.fastforwardlabs.com', image:'kathryn.jpg', twitter:'HumeKathryn'},
		{name:'Lynn Cherny', description:'Lynn Cherny is a data analysis and visualization consultant and currently a visiting Knight Fellow at University of Miami. She has a Ph.D. in Linguistics from Stanford and an M.Phil. in Computer Speech and Language Processing from Cambridge University. Her career began in research in an HCI group at Bell Labs (later AT&T Labs), but she left research to work in industry as a UI designer. She spent 18 years in various UX, UI, and usability roles in Silicon Valley, Paris, Seattle, and Boston, at companies including Excite, TiVo, Adobe, Autodesk, the Mathworks, and Solidworks. ', image:'lynn.jpg', href:'ghostweather.com/', twitter:'arnicas'},
		{name:'Rebecca Fiebrink', description:'Rebecca Fiebrink creates new technologies for digital music and art, and she designs new ways for humans to interact with computers in creative practice. Much of her current research combines techniques from human-computer interaction, machine learning, and signal processing to allow people to apply machine learning more effectively to new problems, such as the design of new digital musical instruments and gestural interfaces for gaming and health. She is a Lecturer in Computing at Goldsmiths, University of London, and was previously an Assistant Professor at Princeton University.', image:'rebecca.jpg', href:'doc.gold.ac.uk/~mas01rf/Rebecca_Fiebrink_Goldsmiths/welcome.html', twitter:'RebeccaFiebrink'},
		{name:'SFPC', description:'The School for Poetic Computation is organized around exploring the creative and expressive nature of computational approaches to art and design. The school approaches writing code like creative writing — focusing on the mechanics of programming, the demystification of tools, and hacking the conventions of art-making with computation. Currently, SFPC is organized by Lauren Gardner, Zach Lieberman and Taeyoon Choi.', image:'sfpc.png', href:'sfpc.io', twitter:'sfpc'},
		{name:'Hannah Davis', description:'Hannah Davis is a programmer/artist/musician based in New York. She is interested in everything, but at the moment is focused on data sonification, generative music, weird datasets, and new ways of exploring abstract systems. She is currently working on TransProse, a program that translates literature into music. She has a master\'s degree from NYU\'s ITP program and her work has been featured in TIME, Wired, Popular Science, and others.', image:'hannah.jpg', href:'hannahishere.com/', twitter:'ahandvanish'}];var peeps2 = [
		{name:'Brian Whitman', description:'Brian Whitman teaches computers about music. He received his PhD from the Machine Listening group at MIT’s Media Lab in 2005 and his masters in Computer Science from Columbia University’s Natural Language Processing group in 2000. His research focuses on the automated understanding of music listeners: parsing the global discussion of music and how fans interact with their favorite artists. In 2005 he co-founded The Echo Nest, and later became its CTO. The Echo Nest’s open platform with trillions of data points about the world of music grew to 70 employees and powered the music intelligence for almost every music service until it was acquired by Spotify in 2014. At Spotify, Brian serves as the Principal Music Scientist, coordinating existing music intelligence efforts and directing R&D for future products.', href:'notes.variogr.am/', image:'brian.jpg', twitter:'bwhitman'},		
		{name:'Francis Tseng', description:'Francis Tseng is a designer and data developer, interested in how automation, simulation, and machine learning relate to social and political issues. In the past he has worked on community data analysis infrastructure for the Coral Project as a Knight-Mozilla OpenNews fellow, dystopian machine learning workshops, taught about journalism and technology at the New School, developed an automated music remixer, and prototyped news automation software under a Knight Prototype grant. He is currently working on interactive economy simulations and visualizations as a DBRS Labs resident.', href:'frnsys.com', image:'francis.jpg', twitter:'frnsys'},
		{name:'Gene Kogan', description:'Gene Kogan is an artist and programmer who is interested in generative systems and the application of emerging technology into artistic and expressive contexts. He writes code for live music, performance, and visual art. He contributes to open-source software projects and gives workshops and demonstrations on topics related to code and art.', image:'gene.jpg', href:'genekogan.com', twitter:'genekogan'},
		{name:'Golan Levin', description:'Golan Levin develops artifacts and experiences which explore the expressive use of computation, combining equal measures of the whimsical, the provocative, and the sublime in a wide variety of online, installation and performance media. A graduate of the Aesthetics and Computation Group at MIT, Golan is presently an Associate Professor of Electronic Art at Carnegie Mellon University, where he also directs the Frank-Ratchye STUDIO for Creative Inquiry, a laboratory dedicated to atypical and anti-disciplinary research at the intersection of art, science, technology and culture.', image:'golan.jpg', href:'flong.com', twitter:'golan'},
		{name:'Jason Levine', description:'Jason Levine is a musician, performer, and computational poet. On a mission to bridge different artistic disciplines, he sees computation as a universal language for translating and communicating between different mediums. Inspired by the need to improvise, Jason focuses on the performative and generative qualities of coding and creates real-time software systems for live performance. He holds a degree in Computer Science and is a graduate of the School for Poetic Computation. He is currently most excited by applying live coding, machine learning, and parallel computing to his artistic practice. Jason has designed generative visuals for Ms Lauryn Hill, 7up, and Twitter.  He has done research for Harmonix’s game Fantasia:Music Evolved and Zach Lieberman\'s DevArt project Play the World and contributed to the CLOUDS documentary. He recently became a Senior Creative Technologist at Local Projects.', image:'jason.png', 'href':'www.behance.net/jasonlevine', 'twitter':'xululululuuum'},		
		{name:'Mario Klingemann', description:'Mario Klingemann is a code artist and a skeptic with a curious mind. His interests are manifold and in constant evolution, involving glitch art, data visualization or robotic installations. If there is one common denominator it\'s his desire to understand, question and subvert the inner workings of systems of any kind. Since he taught himself programming 30 years ago he has been trying to create algorithms that are able to surprise and to show almost autonomous creative behaviour. The recent advancements in artificial intelligence, deep learning and data anaysis make him confident that in the near future "machine artists" will be able to create more interesting work than humans.', image:'mario.jpg', href:'mario-klingemann.tumblr.com/', twitter:'quasimondo'}, 
		{name:'Mike Tyka', description:'Mike Tyka studied Biochemistry and Biotechnology at the University of Bristol and went on to work as a research fellow at the University of Washington, studying the structure and dynamics of protein molecules. In 2009, Mike and a team of artists created Groovik’s Cube, a 35 feet tall, functional, multi-player Rubik’s cube. Since then, he co-founded ATLSpace, an artist studio in Seattle and has been creating metal and glass sculptures of protein molecules. In 2013 Mike went to Google to study neural networks, both artificial and natural. This work naturally spilled over to his artistic interests, exploring the possibilities of artificial neural networks for creating art.', image:'mike.jpg', href:'mtyka.github.io', twitter:'mtyka'}];
		
		// people
		shuffle(peeps);shuffle(peeps2);
		var people=$.map(peeps,function(v,i){return i<peeps2.length?[v,peeps2[i]]:v;});
		for (var p=0; p<people.length; p++) {
			var d = ''+
			'<div class="person" >' +
				'<img class="pic" src="images/'+people[p].image+'" align="right" />' + 
				'<div class="name"> '+
					'<a href="http://'+people[p].href+'">'+people[p].name+'</a>'+
				'</div>' +
				'<div class="description">'+
					people[p].description+
					'&nbsp;&nbsp;&nbsp;<a href="https://www.twitter.com/'+people[p].twitter+'">@'+people[p].twitter+'</a>'+
				'</div>' +
			'</div>';
			$("#d_people").append(d);	
		}
		
		// exhibition works
		var works_l = [
			{names:[{name:"Cassie Tarakajian", href:"cassietarakajian.com"}], external:"", movie:"images/exhibit-cassie", title:"Visualizing Machine Learning", description:"An experience to break down and visualize a machine learning algorithm, specifically a convolutional neural network, in virtual reality. A user can see how her input, a hand-drawn number, is processed and features are extracted by the algorithm to identify the number."},
			{names:[{name:"Harshit Agrawal", href:"harshitagrawal.com/"}, {name:"Arnav Kapur", href:"arnavkapur.com/"}], external:"__", image:"images/exhibit-harshit.jpg", title:"Tandem", description:"Take a human sketch/painting as an input and let a neural network ‘imagine’ on it. The human also communicates to this computer collaborator, some aspects of personality (with a relaxed definition of personality) like happy, sad, dark, even painting styles like cubism etc. The output from the neural network that imagines on the input, is then used as in input in a style transfer implementation that is then presented to the human on top of their input. The human can then tweak their input, and continue this conversation."},
			{names:[{name:"Hannah Davis", href:"www.hannahishere.com"}], external:"", image:"images/exhibit-hannah.jpg", title:"TransProse", description:"TransProse is a program that generates music from novels. It is an experiment in whether it is possible to programmatically translate abstract data (emotions) across mediums. TransProse works by identifying emotions throughout a novel, and using that underlying emotional structure to create musical pieces with the same emotional tone."},
			{names:[{name:"Jason Levine", href:"www.twitter.com/xululululuuum"}], external:"_", image:"images/exhibit-jason.jpg", title:"The Samples Never End", description:"A live-coding musical performance on top of a large collection of audio samples organized and visualized with t-SNE."}, 	
			{names:[{name:"David Lublin", href:"www.davidlubl.in/"}], external:"www.davidlubl.in/blog/2015/tvcommentbot", image:"images/exhibit-david.jpg", title:"TV comment bot", description:"TVCommentBot is a computer program that watches live broadcast TV over the airwaves in real-time and uses image analysis algorithms to improve it with new dialogue for you to enjoy. (Originally created for Art Hack Day: Deluge by David Lublin with Blair Neal and David Newbury). Tune into the <a href=\"https://twitter.com/TVCommentBot\">bot live twitter feed</a>"}, 
			{names:[{name:"Blacki Li Rudi Migliozzi", href:"twitter.com/blackili"}], external:"__", image:"images/exhibit-blacki.jpg", title:"K-Means Equilibria", description:"A visualization of k-means and the landscape of the local minima and maxima the algorithm traverses. K-means is a hill climbing algorithm that while is guaranteed to converge is not necessarily guaranteed to converge to the same place each time. The visualization shows many runs of k-means each with the same input data and parameters, but with different starting conditions. What is illustrated is a landscape of the hills and valleys which k-means traverses when trying to converge onto a set of clusters. This visualization clearly shows the fixed points (stable and unstable points) which k-means converges to and away from. Furthermore at times it is easy to see where the algorithm fails to converge to appropriate solutions. When run using different parameters, this visualization results in a quite diverse set of landscapes. "}, 
			{names:[{name:"Nancy Nowacek", href:"nancynowacek.com"}, {name:"Morgan Hille-Refakis", href:"__"}, {name:"David Sheinkopf", href:"bbqdave.net"}, {name:"Caitlin Sikora", href:"caitlinsikora.com"}, {name:"Gene Kogan", href:"genekogan.com"}], external:"", image:"images/exhibit-nancy.jpg", title:"Body Language", description:"A research work-in-progress that asks the question: how else might code be performed (If not with fingers and keyboard)? If somewhere between sport, hip-hop and sign language that can be passed on the street and in clubs like popular dance, who then, can access and perform coade, and what are its products? Body Language challenges the preconceptions of the technology complex by inserting the body as input device into the increasingly disembodied system. It is a speculative project about the future of the body in a digital world and a working system for capturing and translating physical input into digital output via an artificial neural network."},
			{names:[{name:"Mike Tyka", href:"mtyka.github.io"}], external:"__", image:"images/exhibit-mike2.jpg", title:"Animal Parade", description:"A deepdream-style zoom but with bilateral filtering and stepping through the classes using the Inception network."}, 
			{names:[{name:"Melanie Hoff", href:"www.artdelicorp.com/"}, {name:"Dhruv Mehrotra", href:"www.dhruvmehrotra.info/"}], external:"", image:"images/exhibit-melanie.jpg", title:"Doppelcam", description:"A tool for decontextualizing your surroundings. A window into the uncanny valley. A machine for experiencing digital deja vu. Doppelcam is a visually similar camera. The user takes a picture with the app on their phone and receives an image pulled from the internet that is similar to the one they took in pixel-by-pixel value."},
			{names:[{name:"aaajiao", href:"www.eventstructure.com/"}, {name:"QuanQuan", href:"www.eventstructure.com/"}], external:"eventstructure.com/", movie:"images/exhibit-aaajiao", title:"Typeface // 字体", description:"meaningless font : created by a deep convolutional generative adversarial network (DCGAN) trained on calligraphy collection"},
			{names:[{name:"Corbin Ordel", href:"corbinordelforever.wordpress.com/"}, {name:"Aaron Montoya-Moraga", href:"www.aaronmontoyamoraga.com/"}], external:"__", image:"images/exhibit-corbin.jpg", title:"Piano Die Hard", description:"A piano which plays itself everytime there's an explosion in the film 'Die Hard'"},
			{names:[{name:"Chino Kim", href:"chino.kim/"}], external:"", image:"images/exhibit-chino.jpg", title:"Screeners", description:"Glasses that screen screens, using a convolutional neural network and Wekinator trained to recognize them."}, 
			{names:[{name:"Blair Neal", href:"blairneal.com/"}], external:"__", image:"images/exhibit-blair.jpg", title:"10,000 grocery store items", description:"A t-SNE grid of 10,000 items photographed from a supermarket."},
			{names:[{name:"Nitzan Hermon", href:"byed.it/"}, {name:"Kevin Siwoff", href:"kevinsiwoff.com"}], external:"puddleandrock.com/", image:"images/exhibit-nitzan.jpg", title:"The Puddle and the Rock", description:"A thought experiment about design for AI"}
		];

		var works_r = [
			{names:[{name:"Golan Levin", href:"www.flong.com"}, {name:"Kyle McDonald", href:"www.kylemcdonald.net"}, {name:"David Newbury", href:"www.workergnome.com/"}], external:"", image:"images/exhibit-golan.jpg", title:"Terrapattern", description:"An open-source system to help journalists, citizen scientists, humanitarian workers and other curious people to detect “patterns of interest” in satellite imagery. The project was developed at the Frank-Ratchye STUDIO for Creative Inquiry at CMU, with assistance from Irene Alvarado, Aman Tiwari and Manzil Zaheer, and made possible through funding from the Knight Foundation."},
			{names:[{name:"Phillip Stearns", href:"phillipstearns.wordpress.com"}], external:"", image:"images/exhibit-phillip.jpg", title:"AANN: Artificial Analog Neural Network", description:"An interactive, handmade electronic sculpture that responds to environmental stimuli in a display of light and sound. AANN's structure is a skeletal point-to-point soldered network of analog electronic components designed to approximate biological neural network behavior. The sculpture is a 45 neuron network whose form was influenced in part by multi-layered network models used in neural computing, and by the Fibonacci based branching of natural systems. As guests speak or cast shadows on AANN the abrupt changes in sound and light cause the network to react by producing a series of swoops and chirps, and by illuminating LEDs on active neurons."},
			{names:[{name:"David Ha", href:"otoro.net"}], external:"otoro.net/ml/slimevolley/slimeglass.html", image:"images/exhibit-david-volleyball.jpg", title:"Neural Slime Volleyball", description:"Recurrent neural networks trained with genetic algorithms to play slime volleyball.  The agents learned to play the game entirely through self play, and were not programmed with any prior knowledge about the rules of this game."}, 
			{names:[{name:"David Ha", href:"otoro.net"}], external:"otoro.net/ml/planks/index.html", image:"images/exhibit-david-planks.jpg", title:"Creatures Avoiding Planks", description:"Creatures Avoiding Planks is a web toy demonstrating natural selection. Wee blobby creatures wander around avoiding floating planks, which kill on touch. If one lives long enough, it reproduces, passing on slight variations of its own movement behaviour to the offspring."}, 
			{names:[{name:"Tom White", href:"twitter.com/dribnet"}], external:"", image:"images/exhibit-tom.jpg", title:"Portrait Manifold", description:""}, 
			{names:[{name:"Marcel Schwittlick", href:"mrzl.net/"}], external:"__", image:"images/exhibit-marcel.jpg", title:"Sebastian Zimmerhackl, Julie Peters, Julius Voigt", description:"This work is an experimental approach towards an alternative form of collaboration. When two artists are working on the same canvas, be it digital or analogue, many problems arise. The compromises that emerge due to the limitation of the medium have here been mediated with the help of machine learning techniques. This generative video combines structure with color. The two aspects, form and style were created independently from each other and are interwoven on the dna-level."}, 
			{names:[{name:"Seth Kranzler", href:"sethkranzler.com/"}], external:"", image:"images/exhibit-seth.jpg", title:"Neural Recylce", description:"A camera which detects recyclable items, trained with a convolutional neural network and Wekinator"},
			{names:[{name:"Marcela Nowak", href:"marcelanowak.com/"}], external:"__", image:"images/exhibit-marcela.jpg", title:"Instagram mosaics", description:"A series of photo mosaics automatically generated from recent Instagram photos of key hashtags."},
			{names:[{name:"Lisa Kori", href:"lisakori.net"}], external:"__", image:"images/exhibit-lisa.jpg", title:"Assisted Visions", description:"Last year, researchers published an algorithm that allows the style of one image to be superimposed onto the content of another. Some believe that the ability to mix and match preexisting styles and genres will be an invaluable tool to help creators find their own voice, though some, often in popular debate, argue that technologies that can imitate style threaten to replace rather than assist artists. Assisted Visions is an attempt to methodically use style transfer technology for my personal stylistic development. In doing so, the generated images explore the notion that the process of developing a distinctive personal style could be quantified, modified and accelerated."},
			{names:[{name:"Gene Kogan", href:"genekogan.com"}], external:"", image:"images/exhibit-gene.jpg", title:"Cubist Mirror", description:"A near-real-time style transfer mirror based on 'Perceptual losses for real-time style transfer' from Johnson et al, trained on an unidentified Cubist painting."},
			{names:[{name:"David Ha", href:"otoro.net"}], external:"otoro.net/ml/pendulum-cne/index.html", image:"images/exhibit-david-pendulum.jpg", title:"Inverted Pendulum Balancing Experiment", description:"Neural network evolved to balance a double pendulum.  The system is inherently chaotic, and very sensitive to the initial state. The neural network controller learns how to control the speed and direction of the wheel in order to stabilise the pendulum."}, 
			{names:[{name:"Memo Akten", href:"memo.tv/"}], external:"", image:"images/exhibit-memo.jpg", title:"Keeper of our collective consciousness", description:"A collaboration with Google. Not people working at Google, but actual Google, the search engine. And it’s actually more a collection of prayers."},
			{names:[{name:"Chris Novello", href:"chrisnovello.com/"}], external:"__", image:"images/exhibit-chris.jpg", title:"Zuck's Minions", description:"Portrait of Mark Zuckerberg, drawn by a neural net, in the style of a Facebook shitpost about Minions"}
		];		

		var add_work = function(w, div) {
			var ns = [];
			var l = w.names.length;
			if (l == 1) {
				ns = '<a href="http://'+w.names[0].href+'">'+w.names[0].name+'</a>';
			}
			else if (l == 2) {
				ns = '<a href="http://'+w.names[0].href+'">'+w.names[0].name+'</a> and <a href="'+w.names[1].href+'">'+w.names[1].name+'</a>';
			}
			else {
				for (var p=0; p<w.names.length; p++) {
					ns += '<a href="http://'+w.names[p].href+'">'+w.names[p].name+'</a>'+(p==w.names.length-1?'':(p==w.names.length-2?', and ':', '));
				}
			}
			var d = '<div class="exhibit">' +
				'<div class="exhibit_header"><center>';
			if (w.image == undefined) {
				d+='<video loop autoplay><source src="'+w.movie+'.mp4" type="video/mp4"><source src="'+w.movie+'.webm" type="video/webm"></video>'
			} else {
				d+='<img src="'+w.image+'" />';
			}
			d+='</center></div>'+
				'<h2>'+w.title+'</h2>' +
				'<h3>by '+ns+'</h3>' +
				'<div class="description">' +
					w.description +
				'</div>' +
			'</div>';
			$(div).append(d);
		};
		
		var load_highlight_videos = function() {
			var video_id = [183143247,182417945,182380805,182086399,182062314,181215615,181215614,181211762,181197160,181184806,181050904,181040795];
			shuffle(video_id);
			video_id.unshift(178885036);
			video_id.splice(7, 0, 189974949);
			var html_l = '';
			var html_r = '';
			for (var i=0; i<7; i++) {
				html_l += '<p/><iframe src="https://player.vimeo.com/video/'+video_id[i]+'" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>';
			}
			for (var i=7; i<14; i++) {
				html_r += '<p/><iframe src="https://player.vimeo.com/video/'+video_id[i]+'" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>';
			}
			$("#d_watch_left").append(html_l);
			$("#d_watch_right").append(html_r);
		};
		
			
		$(document).ready(function() {
			if (window.innerWidth < 1200) {
				for (var w=0; w<Math.max(works_l.length, works_r.length); w++) {			
					if (w < works_l.length) {
						add_work(works_l[w], "#d_exhibition_left");
					}
					if (w < works_r.length) {
						add_work(works_r[w], "#d_exhibition_left");
					}
				}
			}	
			else {
				for (var w=0; w<works_l.length; w++) {			
					add_work(works_l[w], "#d_exhibition_left");
				}
				for (var w=0; w<works_r.length; w++) {			
					add_work(works_r[w], "#d_exhibition_right");
				}
				
			}		
			
			if (window.location.hash == "#people") {
		  		goPeople();
			}
			else if (window.location.hash == "#workshops") {
				goWorkshops();
			}
			else if (window.location.hash == "#exhibition") {
				goExhibition();
			}
			else if (window.location.hash == "#schedule") {
				goSchedule();
			}
			else if (window.location.hash == "#contact") {
				goContact();
			}
			else if (window.location.hash == "#tickets") {
				goTickets();
			}
			else if (window.location.hash == "#where") {
				goWhere();
			}
			else if (window.location.hash == "#watch") {
				goWatch();
			}
			else {
				goPeople();
			}
		});

	</script>
</body>
</html>
